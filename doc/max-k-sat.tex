\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[serbian]{babel}
\usepackage{listings}
\usepackage{caption}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[]{algorithm2e}

\title{Optimizacija maksimalne k-zadovoljivosti\\ populacionim metahauristikama\\ \small{Seminarski rad u okviru kursa\\ Računarska inteligencija\\ Matematički fakultet}}

\author{David Dimić, Zorana Gajić \\ daviddimic@hotmail.com, zokaaa\_gajich@bk.ru}

\date{Mart 2019.}

% text width and height
\textwidth 16cm
\textheight 23cm

% distance from the top
\voffset -1.5cm

% distance from the left
\hoffset 0.5cm
\oddsidemargin 0mm

% distance from the bottom
\footskip 1.5cm

\begin{document}

\maketitle  
\tableofcontents
\newpage

\abstract{
%TODO
}

\section{Uvod}
%TODO

\section{Formulacija problema  i reprezentacija rešenja}
Data je formula $F$ u KNF obliku sa $n$ promenjivih $(x_1, x_2, ..., x_n)$ i $m$ klauza. Problem maksimalne k-zadovoljivosti može se definisati na sledeći način:\\ 

Klauza $C_i$ dužine $k$ je disjunkcija $k$ literala: 
$C_i = (x_1  \vee x_2 ... \vee x_k)$, gde je svaki literal promenjiva ili njegova negacija i može se pojavljivati više puta u izrazu.
Cilj je pronaći istinitosne vrednosti promenjivih, valuaciju koja je vektor $\vec{v} = (x_1, x_2, ..., x_n) \in \{ 0,1 \}^n$ tako da ova valuacija maksimizuje broj zadovoljenih klauza u formuli $F$.\\

Ako valuacija zadovoljava formulu, onda se ona naziva modelom formule $F$. Max k-SAT problem može se definisati parom $(\Omega, SC)$, gde je $\Omega$ skup svih potencijalnih rešenja iz $\{0,1\}^n$, vektor $n$ promenjivih, a $SC:\Omega \rightarrow \mathbb{N}$, skor valuacije koji je jednak broju zadovoljenih klauza. Shodno ovome, problem max k-SAT je naći $\vec{v} \in \Omega$ za koje je $SC$ maksimalno:\\
$$\max_{\vec{v} \in \Omega}\{SC(\vec{v})\}$$

Očigledno ima $2^n$ potencijalnih rešenja koji zadovoljavaju formulu $F$. Dokazano je da je problem max k-SAT je NP-kompletan za svako $k>2$. %TODO ref

Za dobar algoritam je takođe važno dobro predstavljanje rešenja. Postoje više načina reprezentacija, ali je ovde odabran prirodna binarna reprezentacija. Svaka čestica je predstavljena binarnim nizom dužine $n$.


%TODO
\section{Evolucioni algoritmi (EA)}
Genetski algoritmi su bazirani na Darvinovoj teoriji evolucije, u kojoj unutar jedne populacije najčešće opstaju najbolje prilagođenje jedinke. Nova generacija jedinki se dobija ukrštanjem jedinki iz prethodne generacije, pri čemu se s vremena na vreme kod nekih jedinki mogu pojaviti mutacije na nekim genima. Evolutivni algoritam ima populaciju koja se sastoji od jednog ili više pojedinaca. Pojedinac, koji se naziva hromozom, sastoji se od gena. U našem slučaju gen predstavlja jedan bit. Hromozom predstavlja kodiranje našeg rešenja. Za svaku jedinku se definiše funkcija prilagođenosti. Nakon inicijalizacije početne populacije, nove generacije jedinki se dobijaju uzastopnom primenom genetskih operatora. Smena generacija se vrši sve dok ne bude ispunjen kriterijum zaustavljanja. \\

% pricica o selekciji, ukrstanju, mutaciji...

\subsection{Pseudokod EA}
U ovom poglavlju predstavićemo osnovni oblik algoritma na kojem se dalje zasnivaju ostale varijante. 

\begin{algorithm}[H]
\SetAlgoLined
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{Formula $F$ u KNF-u, $n$ i $m$}
\Output{Najbolja procenjena valuacija i broj zadovoljenih klauza}
\BlankLine
 inicijalizacija populacije: pozicije i brzine\;
 t = 0; \tcp*[h]{tekuća iteracija}\\
 \While{nije zadovoljen uslov zaustavljanja}{
  t = t + 1\;
  Selekcija jedinki za primenu genetskih operatora\;
  Ukrštanje za izabrane parove jedinki\;
  Mutacija izabranih jedinki\;
  Određivanje funkcije prilagođenosti populacije\;
 }
\caption{Osnovni Evolutivni algoritam}
\end{algorithm}

\subsection{Inicijalizacija rešenja}
Potrebno je da inicijalizujemo hromozome pseudoslučajnim brojevima \{0, 1\}. Veoma važnu ulogu igra odabir parametara.  Parametri mogu biti fiksni ili im se vrednosti mogu na određen način menjati iz generacije u generaciju.

\subsection{Fitnes funkcija}
Tokom različitih varijanti EA algoritama koristile su se različite funkcije prilagođenosti. Prva fitness funkcija koja se sama nameće jeste broj zadovoljenih klauza, koju ćemo koristiti u FlipGA i ASAP algoritmima. Nešto malo komplikovanije funkcije prilagođenosti se koriste u SAWEA I RFEA, koje ćemo objasniti detaljnije kasnije.

\subsection{Lokalna pretraga}

\subsection{Varijante EA algoritma}
Da bismo dobili što bolje rešenje pokušavamo da kombinujemo različite tehnike operatora selekcije, ukrštanja, mutacije i ostale U tabeli možemo da vidimo osnovna svojstva varijanti evolutivnog algoritma.
 
\begin{table}[h!]
\centering
\captionof{table}{Varijante EA algoritma}\label{tab:EA} 
\begin{tabular}{ |p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}
 \hline
 Svojstvo & SAWEA & RFEA & FlipGa & ASAP \\
 \hline
 zamena & $(1, \lambda^*)$ & steady-state & generacijski & $(1 + 1)$ \\
 \hline
 selekcija & - & turnirska & fitnes proporcijalna & - \\
 \hline
 fitness &	$f_{SAW}$ & $f_{REF}$ & $f_{MAXSAT}$ & $f_{MAXSAT}$ \\
 \hline
 ukrštanje & - & - & uniformno & - \\
 \hline
 mutacija & MutOne & knowledge-based & random & random-adaptive \\
 \hline
 lokalna pretraga & - & - & flip heuristika & flip heuristika \\
 \hline
 adaptacija & fitnes & fitnes &  - & tabu lista \\
 \hline
\end{tabular}
\end{table}


\subsubsection{SAWEA}

\subsubsection{RFEA}

\subsubsection{FlipGA}

\subsubsection{ASAP}


\subsection{Rezultati}



\section{Optimizacija rojem čestica (PSO)}
Optimizacija rojem čestica (Particle swarm optimization – PSO) je jedna od tehnika pretraživanja zasnovana na populaciji kao što je genetski algoritam, ali ne koriste evolutivne algoritme kao što su mutacija i ukrštanje.
PSO algoritmi su 1995. godine uveli Kenedi i Eberhart kao alternativu standardnim genetskim algoritmima. \\

Optimizacija rojem čestica je algoritam zasnovan na ponašanju pojedinačnih jedinki unutar određene grupe (na primer, jata ptica ili roja insekata). Ukoliko se, vođeno instiktom, jato prica uputi u određenom smeru u potrazi za hranom, očekivanje je da će čitavo jato slediti upravo onu pticu koja je pronašla izvor hrane. Međutim, i svaka ptica ponaosob može biti vođena sopstvenim instiktom i time na trenutak u potrazi za hranom napustiti jato. Tada se verovatno može desiti da, ukoliko pronađe bolji izvor hrane, čitavo jato upravo krene da sledi tu pticu. \\

PSO pripada skupu algoritama koji se zasnivaju na inteligenciji roja (swarm intelligence). Algoritam radi nad skupom jedinki, koji se naziva rojem. Elementi ovog skupa se nazivaju česticama. 
Svaka čestica predstavlja kandidatsko rešenje optimizacionog problema. Čestice se na unapred definisan način kreću po prostoru pretraživanja. Njihovo kretanje se usmerava imajući u vidu njihovu trenutnu poziciju, njihovu do sada najbolju poziciju, kao i do sada najbolju poziciju čitavog roja. Pod najboljom pozicijom čitavog roja se podrazumeva do sada najbolja pozicija, uzimajući u obzir sva njegova rešenja. Proces se ponavlja dok ne bude zadovoljen kriterijum zaustavljanja, a u svakoj iteraciji se ažurira najbolja vrednost rešenja za svaku česticu, kao i za roj u celini. \\

Neka je dat roj sa $\vec{S}$ čestica. Svaka čestica se sastoji od tri elementa:
\begin{list}{•}{}
	\item Pozicija u prostoru za pretragu $\vec{x_i}$
	\item Brzina, vektor $\vec{v_i}$
	\item Sećanje, koje se koristi za skladištenje elitnih čestica globalne pretrage $\vec{P_g}$, kao i najboljih individualnih rešenja $\vec{P_i}$ koja su do sada pronašle zasebne čestice\\
\end{list}

Nije neophodno da se u budućim populacijama nalazi bilo koji elitni pojedinac, iako svaka čestica u populaciji pokušava da bude blizu svog najboljeg rešenja i globalnog najboljeg rešenja. \\ 


Osnovni oblik PSO algoritma dat je sledećim samoažurirajućim jednačinama: \\ 
\begin{equation}\label{eq:v}
\vec{v_{i}}^{t+1} = w \cdot \vec{v_{i}}^{t} + c_1 \cdot \vec{r_1} \times (\vec{P_{i}}^{t} - \vec{x_{i}}^{t}) + c_2\cdot \vec{r_2} \times (\vec{P_{g}}^{t} - \vec{x_{i}}^{t}) 
\end{equation}

\begin{equation}\label{eq:pos}
\vec{x_{i}}^{t+1} = \vec{x_{i}}^{t} + \vec{v_{i}}^{t+1} 
\end{equation}

Jednačina \ref{eq:v} opisuje kako se ažurira brzina $i$-te čestice, a \ref{eq:pos} koja je sledeća pozicija $i$-te čestice, pri čemu je: 

\begin{list}{•}{}
	\item $w$ - faktor inercije
	\item $c_1, c_2$ - faktori učenja: kognitivna i socijalna
	\item $\vec{v_{id}}^{t}$ - brzina $i$-te čestice u iteraciji $t$ 
	\item $\vec{x_{id}}^{t}$ - pozicija $i$-te čestice u iteraciji $t$ 
	\item $\vec{r_1}, \vec{r_2}$ - pseudoslučajni brojevi iz uniformnog intervala $[0,1]$
	\item $\vec{P_i}$ - najbolje individualno rešenje čestice $i$
	\item $\vec{P_g}$ - trenutno najbolje globalno rešenje\\ 
\end{list}

Kako je max k-SAT problem diskretan potrebno je prilagoditi jednačinu \ref{eq:pos}. Izračunata brzina $\vec{v_{i}}$ je iz $\mathbb{R}^n$, pa je potrebno da se svede na $\{ 0,1 \}^n$. Jedan predlog za ažuriranje položaja čestice, izložen u radu \cite{sigmoid}, dat je sigmoidnom transformacijom. Sada ${v_{i}}^{t}$ predstavlja verovatnoću da bit $x_{i}^{t}$ uzme vrednost 1.  \\

\begin{equation}\label{eq:posSIGMOID}
x_{i}^{t}=\begin{cases}
               1, rand(0,1) < sigmoid(v_{i}^{t})\\
               0, inace\\
            \end{cases}
\end{equation}\label{eq:sigmoid}
\begin{equation}
sigmoid(v_{i}^{t}) = \frac{1}{1+e^{-v_{i}^{t}}}
\end{equation}
 
 
\subsection{Pseudokod PSO}
U ovom poglavlju dat je osnovni oblik algoritma na kojem se zasnivaju ostale varijante i izmene koje će biti detaljnije izložene. Jednu populaciju, odnosno roj, čini unapred određen broj čestica, lista potencijalnih rešenja kao i dodeljene brzine za svaku od njih. 
Kroz iteracije računa se fitnes, aužuriraju se brzine i pozicije čestica dok se ne zadovolji kriterijum zaustavljanja. 
Jedna varijanta (WPSOSAT) uvodi i lokalnu pretragu koja se izvodi umesto ažuriranja pozicija, odnosno jednačine \ref{eq:posSIGMOID}.
Kriterijumi zaustavljanja koji se mogu koristiti u opštem slučaju su: da li je dostignut maksimalan broj unapred zadatih iteracija ili, da li u poslednjih nekoliko iteracija nema značajnog napretka.
U test primerima za koje unapred znamo da je formula zadovoljiva, ili koliko je klauza zadovoljivo, možemo koristiti kriterijum da se dostigao ukupan broj zadovoljivih klauza. \\

\begin{algorithm}[H]
\SetAlgoLined
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{Formula $F$ u KNF-u, $n$ i $m$}
\Output{Najbolja procenjena valuacija i broj zadovoljenih klauza}
\BlankLine
 inicijalizacija populacije: pozicije i brzine\;
 t = 0; \tcp*[h]{tekuća iteracija}\\
 \While{nije zadovoljen uslov zaustavljanja}{
  t = t + 1\;
  \For{$i\leftarrow 0$ \KwTo broj cestica u roju}{
  	Izračunaj $Fitness$($\vec{P_i^t}$)\;
  	Sačuvaj individualni najbolji rezultat kao globalni $\vec{P_g}$\;
  	Ažuriraj brzine na osnovu $\vec{P_i}$ i $\vec{P_g}$\;
  	Ažuriraj pozicije $\vec{v_i^t}$\;
  	Ažuriraj individualni najbolji rezultat $\vec{P_i}$\;
  	Ažuriraj globalni najbolji rezultat $\vec{P_g}$\;
  }
 }
\caption{Osnovni PSO algoritam}
\end{algorithm}


\subsection{Inicijalizacija rešenja}
Potrebno je inicijalizovati pozicije čestica i vektora brzine. Pozicije su inicijalizovane pseudo-slučajnim brojevima $\{0,1\}$, a vektor brzine realnim brojevima iz intervala $[-V_{min}, V_{max}]$, gde su granice intervala jedan od parametara PSO algoritma.


\subsection{Fitnes funkcija}
Fitnes funkcija je veoma važna za perfomanse algoritma.
Prva fitnes funkcija koja se sama nameće jeste broj zadovoljenih klauza, kakva je data u samoj formulaciji problema, ali se takva funkcija nije pokazala kao dovoljno dobra. Bolji mehanizam je stepenasto ažuriranje težina (SAW - stepwise adaptation weights) uvedena od strane Eiben-a \cite{fitnes}. Ona je data sledećim formulama:

\begin{equation}\label{eq:SAW}
F_{SAW}(x) = \sum_{i=1}^{m} W_iC_i(x)
\end{equation}

\begin{equation}\label{eq:wForSAW}
W_{i+1} = W_{i} + 1 - C_i(x^*)
\end{equation}

Svakoj klauzi $C_i$ dodeljuje se težina $W_i$. Ova funkcija ima za cilj identifikovanje težih klauza u procesu učenja koja je predstavljena većom vrednošću $W_i$. Na početku su težine inicijalizovane na 1, pa se potom ažuriraju jednačinom \ref{eq:wForSAW}. $x^*$ je tekuće najbolje rešenje.


\subsection{Lokalna pretraga i flip heuristika}
Da bi se unapredio standardni PSO algoritam uvedena je, umesto ažuriranja pozicija čestice jednačinom \ref{eq:posSIGMOID}, stohastička lokalna pretraga heuristikom okretanja bitova (eng.~{\em flip heuristic}).
Ova heuristika zasniva se na izmeni pojedinačnih bitova u tekućem rešenju. Za svaki bit u čestici pokušava se njegovo okretanje. Ako sa tom izmenom ima dobiti (u smislu ne pogoršavanja funkcije cilja) čuva se nova vrednosti okrenutog bita, dok se u suprotnom vraća na njegovu staru vrednost. 
Čitav proces se ponavlja dokle god ima napretka, ako je bar jedna izmena poboljšala tekuće rešenje.

%TODO tabu list

\begin{algorithm}[H]
\SetAlgoLined
\SetKwInOut{Input}{Input}
\SetKwInOut{Output}{Output}

\Input{pozicija čestice $p$, Formula $F$ u KNF-u, maxFlip}
\Output{nova pozicija čestice $p$}
\BlankLine
 improvement = 1\;
 numFlip = 0\;
 \While{$improvement > 0$ and $numFlip < maxFlip$}{
  improvement = 0\;
  \For{$i\leftarrow 0$ \KwTo n}{
  	flip p[i]\;
  	numFlip += 1\;
  	Izračunaj dobit: gain\;
  	\If{$gain>=0$}{
		prihvati flip\;
		improvement += gain\;  	
  	}
  	\Else {
		odbaci flip, vrati na staru vrednost $p[i]$\; 
  	}

  }
 }
 \caption{Funkcija lokalne pretrage}
\end{algorithm}



\subsection{Varijante PSO algoritma}
Da bismo uporedili kombinaciju lokalne pretrage, SAW fitnes funkcije i klasičnog PSO algoritma implementirani su i testirane sledeće tri verzije: \\

%TODO
\subsubsection{PSO-LS}

\subsubsection{PSOSAT}

\subsubsection{WPSOSAT}


PSO-LS - Osnovna varijanta algoritma koji ne koristi lokalnu pretragu, već sigmoidnu transformaciju, jednačine \ref{eq:v} i \ref{eq:posSIGMOID} za ažuriranje brzina i pozicije čestica. Fitnes funkcija je $F_{SAW}$, sa korišćenjem težina nad klauzama. Karakteriše ga sporija konvergencija do globalnog optimuma, ali pojedinačne iteracije se izvršavaju brže.\\

PSOSAT - Koristi lokalnu pretragu, ali ne i $F_{SAW}$, pa je funkcija cilja broj zadovoljenih klauza. Mana ovog algoritma je teško izlaženje iz lokalnih optimuma zbog korišćenja fitnes funkcije koja ne raznanaje težinu klauza.\\

WPSOSAT - Modifikovan PSO algoritam sa korišćenjem flip heuristike i $F_{SAW}$ fitnes funkcije. Značaj lokalne pretrage ogleda se u poređenju sa PSO-LS, a korišćenje $F_{SAW}$ u poređenju sa PSOSAT.\\

\subsection{Rezultati}
%TODO
Svi algoritmi pokretani su pet puta sa istim parametrima i beležen je prosečan broj zadovoljenih klauza, pri čemu podebljan rezultat označava da se do rešenja dolazilo u prvoj iteraciji. U tabeli \ref{tab:UNSAT} skoro svi algoritmi su uspeli da brzo nađu rešenje. Za sada između PSOSAT i WPSOSAT nema razlike. Već za poslednji test vidi se slabost ne korišćenja lokalne pretrage. Već u tabeli \ref{tab:SAT} PSO-LS nije mogao da se uporedi sa ostala dva algoritma. Za neke instance do globalnog optimuma došao je jedino WPSOSAT odakle se vidi značaj SAW funkcije.

\begin{table}[h!]
\centering
\captionof{table}{Parametri}\label{tab:parametri} 
\begin{tabular}{ |p{3cm}|p{2cm}| }
 \hline
 Parametar 	& Vrednost\\
 \hline
 Broj iteracija & 1000 \\
 \hline
 w 				& 1\\
 \hline
 c1 			& 1.7\\
 \hline
 c2				& 2.1\\ 
 \hline
 Broj čestica	& 20\\
 \hline
 max flip & 30000 \\
 \hline
 $v_{min}$ 		& -1\\
 \hline
 $v_{max}$		& 1\\ 
 \hline
\end{tabular}
\end{table}


\begin{table}[h!]
\centering
\captionof{table}{AIM nezadovoljivi testovi}\label{tab:UNSAT}
\begin{tabular}{ |p{3cm}|p{2cm}|p{2cm}||p{2cm}|p{2cm}|p{2cm}| }
 \hline
 Instanca & Broj literala & Broj klauza & PSO-LS & PSOSAT & WPSOSAT\\
 \hline
 aim-50-1\_6-no & 50 & 80 & 79 & \textbf{79} & \textbf{79}\\
 \hline
 aim-50-2\_0-no & 50 & 100 & 99 & \textbf{99} & \textbf{99}\\
 \hline
 aim-100-1\_6-no & 100 & 160 & 159 & \textbf{159} & \textbf{159}\\
 \hline
 aim-100-2\_0-no & 100 & 200 & 199 & \textbf{199} & \textbf{199}\\
 \hline
 aim-200-2\_0-yes & 200 & 400 & 398.6 & \textbf{399} & \textbf{399}\\
 \hline
\end{tabular}
\end{table}

\begin{table}[h!]
\centering
\captionof{table}{AIM zadovoljivi testovi}\label{tab:SAT} 
\begin{tabular}{ |p{3cm}|p{2cm}|p{2cm}||p{2cm}|p{2cm}|p{2cm}|  }
 \hline
 Instanca & Broj literala & Broj klauza & PSO-LS & PSOSAT & WPSOSAT\\
 \hline
 aim-50-1\_6-yes & 50 & 80 & 79 & 79.2 & 80\\
 \hline
 aim-50-2\_0-yes & 50 & 100 & 99 & 99 & 100\\
 \hline
 aim-50-3\_4-yes & 50 & 170 & 168.6 & 170 & 170\\
 \hline
 aim-50-6\_0-yes & 50 & 300 & 300 & 300 & 300\\
 \hline
 \hline
 aim-100-1\_6-yes & 100 & 160 & 158.6 & 159 & 159\\
 \hline
 aim-100-2\_0-yes & 100 & 200 & 198 & 199 & 200\\
 \hline
 aim-100-3\_4-yes & 100 & 340 & 328 & 339.4 & 340\\
 \hline
 aim-100-6\_0-yes & 100 & 600 & 580.2 & \textbf{600} & \textbf{600}\\
 \hline
 \hline
 aim-200-2\_0-yes & 200 & 400 & 395.4 & 399 & 399\\
 \hline
 aim-200-6\_0-yes & 200 & 1200 & 1135.6 & \textbf{1200} & \textbf{1200}\\
 \hline
\end{tabular}
\end{table}



\section{Zaključak}
%TODO

\newpage
\begin{thebibliography}{9}
\bibitem{sigmoid} Kennedy J, Eberhart RC. “A discrete binary version of the particle swarm algorithm,” In: Proceedings of IEEE conference on systems, man and cybernetics , p. 4104–4109, 1997.
\bibitem{fitnes} Gottlieb J, and Voss N. “Adaptive fitness functions for the satisfiability problem”. In: Parallel Problem Solving from Nature - PPSN VI 6th International Conference, Paris, France. Springer Verlag. LNCS 1917, 2000.
\bibitem{} Abdesslem Layeb, “A particle swarm algorithm for solving the maximum satisfiability problem”, MISC Lab., Computer science department, University mentouri of Constantine, Algeria
\end{thebibliography}

\end{document}
